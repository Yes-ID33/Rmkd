---
title: "AnalisisEstadisticoTaller2"
output: 
  html_document:
    toc: TRUE
    toc_depth: 3
    toc_float: TRUE
    collapsed: TRUE
    smooth_scroll: TRUE
    theme: cerulean
    df_print: paged
    code_folding: show
    
date: "2024-10-24"

author: "Laura Castillo, Valentina Loaiza, Cristina Sierra"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(plotly)
library(MASS)
library(psych)
library(factoextra)
library(GGally)
library(dplyr)
library(ggplot2)
library(cluster)


```

# Visualización de los datos

```{r}

dfEnergiaPaises <- read.csv("./datos_taller_02.csv", header = TRUE, sep=';')

dfEnergiaPaises

```

#### Para este trabajo se utilizaron como 5 variables de interes, variables relacionadas con el consumo de energias de todo tipo, tanto fosiles como de electricidad.


# **Primera parte** 
> (Los valores atipicos existen, por lo cual multiples filas de datos pueden tener una afeccion significativa a datos medios)

## Punto 1

> Encuentre la estimación del vector de medias y la matriz de varianzas y covarianzas para 5 variables de su interés del conjunto de datos.

```{r}


# Select the 5 variables of interest
selected_data <- dfEnergiaPaises[, c("Distillate_fuel_oil_consumption_TBPD","Jet_fuel_consumption_TBPD", "Motor_gasoline_consumption_TBPD","Petroleum_and_other_liquids_consumption_TBPD","Electricity_net_consumption_BKWH")]

# Calculate the mean vector
prom_vector <- colMeans(selected_data, na.rm = TRUE)

# Calculate the variance-covariance matrix
var_cov_matrix <- cov(selected_data, use = "complete.obs")

# Display the results
print("Vector de los promedios:")
print(prom_vector)

print("Variance-Covariance Matrix:")
print(var_cov_matrix)

```

## Punto 2

> Realice un análisis descriptivo univariado y bivariado del conjunto de datos. Considere nuevamente las mismas 5 variables de su interés para este punto.


> El análisis descriptivo univariado examina cada variable de forma independiente, produciendo métricas resumidas como la media, la mediana, la desviación estándar y los valores mínimo y máximo. Este análisis facilita la identificación de patrones básicos, distribuciones y posibles valores atípicos para cada variable seleccionada relacionada con el consumo de energía. 

```{r}
#Análisis descriptivo univariado
summary(selected_data)
```


> El análisis descriptivo bivariado investiga las relaciones entre pares de variables, ofreciendo una comprensión más profunda de sus interacciones. Mediante el empleo de matrices de diagramas de dispersión (ggpairs), se visualizan las correlaciones y tendencias entre pares de variables de interés. Este enfoque permite observar relaciones lineales, agrupaciones potenciales y tendencias entre las variables seleccionadas, lo cual es esencial para comprender cómo se asocian los diferentes tipos de consumo de energía en los países.

```{r}

#Análisis descriptivo bivariado relaciones par-par

ggpairs(selected_data)

```




## Punto 3

> El conjunto de datos incluye 57 variables, analizarlas de forma individual podría representar un gasto computacional y de tiempo bastante agotador; por lo cuál una técnica de reducción de dimensionalidad sería ideal. Ejecute un ACP sobre estos datos, compare la contribución de las variables sobre el primer plano factorial de un ACP normado (escalado) y uno sin normalizar (sin escalar).

```{r}
# Remove country column (assuming the first column contains country names)
# We'll only apply PCA to the numeric variables
df_numeric <- dfEnergiaPaises[, -1] # This removes the first column (country names)

# Standardizing the data for PCA
standardized_data <- scale(df_numeric)

# PCA with standardized data
pca_standardized <- prcomp(standardized_data, scale = TRUE)
fviz_pca_var(pca_standardized, axes = c(1, 2), repel=TRUE, labelsize=1)

# PCA without standardization
pca_non_standardized <- prcomp(df_numeric, scale = FALSE)
fviz_pca_var(pca_non_standardized, axes = c(1, 2), repel=TRUE, labelsize=1)


```

> Cuando los datos estan estandarizados (En este caso se uso min-max para obtener valores entre 0 y 1) se puede obseravar su distribución que tiende a datos medios donde hay unas variables (columnas) que sobresalen en su grafico, en su contra parte cuando no estan estandarizados se vuelve mas caotico por la diferencia de valores que hay entre cada uno de las variables.

> Con un ACP podemos obtener los datos que son mas utiles (los mas cercanos al medio) ayudandonos a hacer una mejor filtración de datos.s

### Datos estandarizaddos

```{r}
summary(pca_standardized)
```

### Datos **NO** estandarizados

```{r}
summary(pca_non_standardized)

```



## Punto 4

> Una vez calculado el PCA normado, ¿qué número de componentes principales deberíamos seleccionar? ¿Bajo que criterio seleccionó este número de componentes?

```{r}
# Visualizing the cumulative variance explained by each principal component
fviz_eig(pca_standardized)

# Using Kaiser criterion to select components with eigenvalues > 1
eigenvalues <- pca_standardized$sdev^2
selected_components <- sum(eigenvalues > 1)
selected_components
```
> 4. conclusión

>Basado en el PCA normado (estandarizado), deberíamos seleccionar el número de componentes principales basándonos en los siguientes criterios:

> 1. **Criterio de Kaiser**: Debemos seleccionar los componentes cuyos eigenvalores sean mayores a 1. 
    - Los componentes con eigenvalores mayores a 1 explican más varianza que cualquier variable original y se consideran significativos.
    - Esto ayuda a reducir la dimensionalidad mientras se conservan componentes significativos. Después de calcular los eigenvalores, retenemos aquellos donde λ > 1.

> 2. **Umbral de Varianza Explicada**: Otro enfoque es retener suficientes componentes para explicar una proporción suficiente de la varianza (por ejemplo, 80% o 90% de la varianza acumulada).
    - Se puede visualizar la varianza explicada usando un scree plot y observar el punto donde agregar más componentes comienza a contribuir muy poca varianza adicional (punto de "codo").
    - El número de componentes seleccionados bajo este criterio es donde alcanzamos el porcentaje deseado de varianza acumulada.

> Decisión Final: Usando tanto el criterio de Kaiser como el umbral de varianza explicada, decidimos el número óptimo de componentes, equilibrando la simplicidad y la preservación de la varianza.

## Punto 5

> Analice la representación de las variables originales sobre las dos primeras componentes en el primer plano factorial. ¿Que conclusiones podemos sacar de este análisis?

```{r}
# Load necessary libraries
library(factoextra)

# Perform PCA on the standardized dataset (excluding the country column)
df_numeric <- dfEnergiaPaises[, -1] # Remove country column
pca_result <- prcomp(scale(df_numeric))

# Visualize the variables on the first factorial plane (PC1 vs PC2)
# Selecting only the top 30 most contributing variables to avoid clutter
fviz_pca_var(pca_result, 
             axes = c(1, 2),        # Focus on PC1 and PC2
             select.var = list(contrib = 12),  # Select the top 30 contributing variables
             repel = TRUE,           # Avoid label overlap
             labelsize = 2)          # Decrease label size to avoid saturation

```
> 5. Conclusión:

> Este análisis nos permite visualizar cómo las variables originales están representadas en el primer plano factorial, formado por las dos primeras componentes principales (PC1 y PC2). Al filtrar las 30 variables que más contribuyen y ajustar el tamaño de las etiquetas, podemos identificar mejor cuáles son las variables que tienen la mayor influencia en estas componentes.

>Las variables con flechas más largas o que se encuentran más alejadas del centro son las que más contribuyen a la variabilidad explicada por estas componentes principales. Estas componentes son importantes porque capturan la mayor parte de la varianza del conjunto de datos. A partir de este análisis, podemos concluir qué variables son clave para explicar las diferencias entre los países en términos de su consumo y producción energética.

## Punto 6

> Ahora examine con detenimiento el mapa de individuos sobre los planos factoriales que conforman las componentes (1,2) y (2,3). ¿Qué conclusiones puede sacar según la cercanía de algunas UE?

```{r}
# Visualización de los países (individuos) en el segundo plano factorial (PC1 vs PC2)
fviz_pca_ind(pca_result, 
             axes = c(1, 2),        # Nos centramos en PC1 y PC2
             repel = TRUE,           # Evita la superposición de etiquetas
             labelsize = 3)          # Ajuste del tamaño de las etiquetas

# Visualización de los países (individuos) en el primer plano factorial (PC3 vs PC4)
fviz_pca_ind(pca_result, 
             axes = c(3, 4),        # Nos centramos en PC1 y PC2
             repel = TRUE,           # Evita la superposición de etiquetas
             labelsize = 3)          # Ajuste del tamaño de las etiquetas

```

> 6 Conclusión:

> Se puede concluir que en los 2 distintos planos, hay 4 países(individuos) que destacan que son China(21), Rusia(79), Saudi Arabia(80), USA(104), ya que en ambos planos son muy atípicos, aunque en el segundo hay otros que también son atípicos pero en conjunto no llegan a los 4 anteriormente mencionados, siendo así que sin estos, 4 individuos, todos los países estarían en un rango promedio de no demasiado uso de las energías y/o combustibles


## Punto 7

> Como hemos observado en clase, el ACP es una técnica bastante sensible a datos atípicos, ejecute nuevamente el ACP retirando del conjunto de datos a Estados Unidos, China, Arabia Saudi y Rusia. ¿En que cambia el ACP al excluir estos países?. ¿Se perciben clusters de países con mayor claridad?. **Calcule únicamente el ACP normado.**

```{r}
# Crear el nuevo dataframe excluyendo los países atípicos basados en sus índices (China, Rusia, Arabia Saudita, USA)
dfEnergiaPaisesBounded <- dfEnergiaPaises[-c(21, 79, 80, 104), ]

# Eliminar la columna de países para el ACP, ya que no es numérica
df_numeric_cleaned <- dfEnergiaPaisesBounded[, -1]  # Excluir la columna de nombres de países

# Estandarizar los datos (normado)
df_scaled_cleaned <- scale(df_numeric_cleaned)

# Realizar el ACP normado
pca_cleaned <- prcomp(df_scaled_cleaned)

# Visualizar la representación de las variables en el primer plano factorial (PC1 vs PC2)
fviz_pca_var(pca_cleaned, axes = c(1, 2), repel = TRUE, labelsize = 4)

# Visualizar la representación de los países (individuos) en el primer plano factorial (PC1 vs PC2)
fviz_pca_ind(pca_cleaned, axes = c(1, 2), repel = TRUE, labelsize = 4)

# Visualizar los países en el segundo plano factorial (PC2 vs PC3)
fviz_pca_ind(pca_cleaned, axes = c(2, 3), repel = TRUE, labelsize = 4)
```

> 7. Respuestas:

> al tener menos valores atípicos es más fácil visualizar grupos con distancias más pequeñas entre si
se perciben clusters de países con mayor claridad? 

> Si, como las dimensiones ya tienen un menor porcentaje de peso total en cuanto a los datos, es más fácil ver grupos que coincidan entre D1 y D2 y sea más fácil ubicar un cluster de prueba uno mismo y agruparlos

# **Segunda parte** 
> (Eliminando Rusia, China, Arabia Saudita y USA debido a su afectacion a las correlaciones de los datos)

## Punto 8

> De acuerdo a lo aprendido en la clase de agrupamiento, utilice el primer plano factorial para determinar de manera aproximada el número de grupos en el análisis. ¿Cuántos clusters espera que existan en el conjunto de datos?

```{r}
# Visualización del primer plano factorial (PC1 vs PC2)
fviz_pca_ind(pca_cleaned, axes = c(1, 2), repel = TRUE, labelsize = 4)

# Observamos el gráfico y contamos los posibles clusters que parecen formarse.

```

> 8. Respuestas:

> en donde hay más datos se pueden sacar 3 o 4 clusters, algunos atípicos podrían convertir este número en 5 o 6, incluso 7 si nos ponemos muy estrictos

## Punto 9

> Mediante el método de reducción de varianza explicada, determine un número fijo de clusters para su análisis. No tiene que ser el mismo número que el elegido por su compañero, recuerde que ninguno conoce las etiquetas reales de los grupos de los países.

```{r}
# Definir un rango de clusters para analizar
max_clusters <- 10  # Cambié el límite a 10, ya que tienes una iteración hasta 11
wss <- numeric(max_clusters)  # Almacenar la suma de las distancias dentro de los clusters

# Calcular la suma de las distancias dentro de los clusters para cada número de clusters (k)
for (k in 1:max_clusters) {
  km_result <- kmeans(df_scaled_cleaned, centers = k, nstart = 33)
  wss[k] <- km_result$tot.withinss
}

# Graficar el método del codo
plot(1:max_clusters, wss[1:max_clusters], type = "b", pch = 19, frame = FALSE,
     xlab = "Número de Clusters (k)", 
     ylab = "Suma de las Distancias Dentro de los Clusters (WSS)")


```

> 9. conclusiones

> entre 4 y 6 clusters es la respuesta correcta


## Punto 10

> Determine mediante k-means y aglomeración jerárquica (usando enlace promedio) la clasificación en grupos para los países de estudio. Considere todas las variables de estudio ¿son diferentes los resultados de los dos análisis cluster?

```{r}

# K-means Clustering
set.seed(123)  # Para reproducibilidad
k <- 3  # Elegimos 4 clusters como ejemplo, ajústalo según el análisis anterior
kmeans_result <- kmeans(df_scaled_cleaned, centers = k, nstart = 25)

# Agregar los resultados de k-means al dataframe original
dfEnergiaPaisesBounded$KMeans_Group <- as.factor(kmeans_result$cluster)


# Aglomeración Jerárquica

# Calculando la distancia y realizando el clustering jerárquico
dist_matrix <- dist(df_scaled_cleaned)  # Matriz de distancias
hclust_result <- hclust(dist_matrix, method = "average")  # Aglomeración jerárquica
clusters_hclust <- cutree(hclust_result, k)  # Cortar en 3 clusters

# Agregar los resultados de aglomeración jerárquica al dataframe
dfEnergiaPaisesBounded$HCLUST_Group <- as.factor(clusters_hclust)

# Comparar los grupos obtenidos
table(dfEnergiaPaisesBounded$KMeans_Group, dfEnergiaPaisesBounded$HCLUST_Group)

```

> 10. conclusiones

> Se evidencia que en el cluster 2 es donde se agrupan la mayor cantidad de datos, es por eso que los clusters restantes cuentan con un valor menos significativo de datos


## Punto 11

> Grafique mediante boxplot la distribución de las 5 variables seleccionadas en el punto 2 diferenciando por los grupos encontrados mediante k-means (es decir, obtenga un boxplot por variable y por grupo: si por ejemplo k-means indica un total de 3 grupos, realice 3 boxplots, uno por grupo, para cada una de las 5 variables). ¿Observa diferencias importantes entre las distribuciones por grupos de la misma variable?

```{r}
# Select the 5 variables of interest from dfEnergiaPaisesBounded
selected_data <- dfEnergiaPaisesBounded[, c("Distillate_fuel_oil_consumption_TBPD","Jet_fuel_consumption_TBPD", "Motor_gasoline_consumption_TBPD","Petroleum_and_other_liquids_consumption_TBPD","Electricity_net_consumption_BKWH")]

# Standardize the selected data for clustering
selected_data_scaled <- scale(selected_data)

# Perform k-means clustering with the selected data from dfEnergiaPaisesBounded
set.seed(123)  # For reproducibility
kmeans_result <- kmeans(selected_data_scaled, centers = 3, nstart = 25)  

# Assign the cluster labels to dfEnergiaPaisesBounded
dfEnergiaPaisesBounded$cluster <- as.factor(kmeans_result$cluster)

# Create boxplots for each variable, differentiated by cluster
for (variable in colnames(selected_data)) {
  p <- ggplot(dfEnergiaPaisesBounded, aes(x = cluster, y = .data[[variable]], fill = cluster)) +
    geom_boxplot() +
    labs(title = paste("Boxplot of", variable, "by K-means clusters"), 
         x = "Cluster", y = variable) +
    theme_minimal() +
    theme(legend.position = "none") +
    scale_fill_brewer(palette = "Set3")
  
  # Explicitly print the plot
  print(p)
}

```

> 11. conclusiones

>  Se puede observar en el primer cluster estan los paises con un mayor consumo, acaparado una variabilidad muy alta uno a otro, en el segundo cluster estan los paises con un consumo moderado en donde se presenta una menor dispercion y por último, el cluster 3 presenta paises debajo de la media de consumo en todos los casos.

> En los 5 graficos clusterizados se nota el patron de que siempre el primer cluster es el que presenta mayor diferencia entre sus valores y que este difiere mucho con sus valores al de el último cluster en donde los consumos son fracciones del primero




